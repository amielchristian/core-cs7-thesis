{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from vit_keras import vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (512, 512)\n",
    "batch_size = 2\n",
    "accumulation_steps = 16 // batch_size # this simulates a batch size of batch_size*accumulation_steps = 16\n",
    "input_shape = image_size + (3,)\n",
    "learning_rate = 2e-4\n",
    "epochs = 25\n",
    "alpha = 0.75\n",
    "beta = 0.1\n",
    "temperature = 3.0\n",
    "spatial_alignment_layers = 2\n",
    "seed = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_data(image_size, batch_size):\n",
    "    data_dir = '/mnt/c/Users/Ann Clarisse Salazar/Documents/project/train_zscore'\n",
    "\n",
    "    labels_df = pd.read_csv('/mnt/c/Users/Ann Clarisse Salazar/Documents/project/data/train_labels.csv')\n",
    "    labels_df['image'] = labels_df['image'].apply(lambda x: f\"{data_dir}/{x}.jpeg\")\n",
    "    labels_df['level'] = labels_df['level'].astype(str)\n",
    "\n",
    "    train_data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=360,  # Random rotation up to 90 degrees\n",
    "        width_shift_range=0.2,  # Random horizontal shift\n",
    "        height_shift_range=0.2,  # Random vertical shift\n",
    "        zoom_range=[0.87, 1.15],\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        horizontal_flip=True,  # Random horizontal flip\n",
    "        vertical_flip=True,  # Random vertical flip\n",
    "        validation_split=0.2,\n",
    "        fill_mode='constant'\n",
    "    )\n",
    "\n",
    "    # Define data augmentation for validation (only rescaling)\n",
    "    val_data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.2,\n",
    "    )\n",
    "\n",
    "    # Load training dataset with augmentation\n",
    "    train_ds = train_data_augmentation.flow_from_dataframe(\n",
    "        dataframe=labels_df,\n",
    "        x_col='image',\n",
    "        y_col='level',\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        subset='training',\n",
    "        seed=seed,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Load validation dataset without augmentation\n",
    "    val_ds = val_data_augmentation.flow_from_dataframe(\n",
    "        dataframe=labels_df,\n",
    "        x_col='image',\n",
    "        y_col='level',\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        subset='validation',\n",
    "        seed=seed,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_ds, val_ds\n",
    "\n",
    "# Load the data\n",
    "train_ds, val_ds = load_data(image_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = vit.vit_b16(\n",
    "    weights='imagenet21k+imagenet2012',\n",
    "    image_size = 512,\n",
    "    pretrained=True,\n",
    "    pretrained_top=False,\n",
    "    classes=5,\n",
    ")\n",
    "\n",
    "data_dir = '/mnt/c/Users/Ann Clarisse Salazar/Documents/project'\n",
    "model_folder= \"FinalModels/teacher_resnet\"\n",
    "config_json = f'{data_dir}/{model_folder}/config.json'\n",
    "model_path = f'{data_dir}/{model_folder}/model.weights.h5'\n",
    "teacher = tf.keras.applications.ResNet50V2(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_shape=(512, 512, 3),\n",
    "    classes=5\n",
    ")\n",
    "x = teacher.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(5)(x)\n",
    "\n",
    "teacher = Model(teacher.input, x)\n",
    "teacher.load_weights(model_path)\n",
    "teacher.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_distillation import Distiller\n",
    "\n",
    "teacher.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "total_steps = epochs * 14051\n",
    "\n",
    "cosine_decay_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=learning_rate, decay_steps=total_steps, alpha=2e-6\n",
    ")\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "distiller.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=cosine_decay_fn, gradient_accumulation_steps=accumulation_steps),\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "    ],\n",
    "    student_loss_fn=keras.losses.CategoricalCrossentropy(),\n",
    "    logit_loss_fn=keras.losses.KLDivergence(),\n",
    "    feature_loss_fn=keras.losses.CosineSimilarity(),\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    temperature=temperature,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import shutil\n",
    "from tensorflow.keras.callbacks import Callback, BackupAndRestore\n",
    "\n",
    "# Define model_id and log_dir\n",
    "model_id = \"GAMEKD\"+distiller.name + '_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(f\"Model ID: {model_id}\")\n",
    "log_dir = f\"/mnt/c/Users/Ann Clarisse Salazar/Documents/project/records_kd/{model_id}/logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_run_time = None\n",
    "array = []\n",
    "\n",
    "# if training is resumed\n",
    "log_file = f'resume_epoch_logs_{model_id}.json'\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as f:\n",
    "        array = json.load(f)\n",
    "        print(array)\n",
    "        \n",
    "# Define a callback to log the final epoch\n",
    "class FinalEpochLogger(Callback):\n",
    "    def __init__(self, log_file=f'resume_epoch_logs_{model_id}.json'):\n",
    "        super(FinalEpochLogger, self).__init__()\n",
    "        self.log_file = log_file\n",
    "        array = self.load_logs()\n",
    "        self.total_time = self.load_elapsed_time()\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.time_start = datetime.datetime.now()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.update_elapsed_time()\n",
    "        self.save_elapsed_time()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.update_elapsed_time()\n",
    "        self.time_start = datetime.datetime.now()\n",
    "\n",
    "    def update_elapsed_time(self):\n",
    "        self.time_end = datetime.datetime.now()\n",
    "        elapsed_time = (self.time_end - self.time_start).total_seconds()\n",
    "        self.total_time += elapsed_time\n",
    "\n",
    "    def save_elapsed_time(self):\n",
    "        elapsed_time_file = self.log_file.replace('.json', '_elapsed_time.json')\n",
    "        with open(elapsed_time_file, 'w') as f:\n",
    "            json.dump(self.total_time, f)\n",
    "\n",
    "    def load_elapsed_time(self):\n",
    "        elapsed_time_file = self.log_file.replace('.json', '_elapsed_time.json')\n",
    "        if os.path.exists(elapsed_time_file):\n",
    "            with open(elapsed_time_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        array.append(f\"Epoch {epoch+1}: {logs}\\n\")\n",
    "        self.save_logs()\n",
    "\n",
    "    def save_logs(self):\n",
    "        with open(self.log_file, 'w') as f:\n",
    "            json.dump(array, f)\n",
    "\n",
    "    def load_logs(self):\n",
    "        if os.path.exists(self.log_file):\n",
    "            with open(self.log_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return []\n",
    "final_epoch_logger = FinalEpochLogger()\n",
    "backup_dir = './backup'\n",
    "backup_callback = BackupAndRestore(backup_dir=backup_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller.build(input_shape)\n",
    "distiller.fit(train_ds,\n",
    "              epochs=epochs,\n",
    "              validation_data=val_ds,\n",
    "              # steps_per_epoch=steps_per_epoch,\n",
    "              callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, mode='max'),\n",
    "                tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "                final_epoch_logger,\n",
    "                backup_callback\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runtime = final_epoch_logger.total_time\n",
    "#make total runtime in HH: MM: SS format\n",
    "total_runtime = str(datetime.timedelta(seconds=total_runtime))\n",
    "print(f\"Total runtime: {total_runtime} hours\")\n",
    "print(log_dir)\n",
    "# Save the model\n",
    "os.makedirs(f\"/mnt/c/Users/Ann Clarisse Salazar/Documents/project/records_kd/{model_id}\", exist_ok=True)\n",
    "distiller.student.save(f'/mnt/c/Users/Ann Clarisse Salazar/Documents/project/records_kd/{model_id}/model_{model_id}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "note = f\"NOTE: cam_kd, {spatial_alignment_layers} spatial alignment layers, limited set, {beta} beta, use base vit with pretraining, no cams, base KD\"\n",
    "\n",
    "# Create a StringIO object to capture the output\n",
    "output_capture = io.StringIO()\n",
    "\n",
    "# Redirect stdout to the StringIO object\n",
    "sys.stdout = output_capture\n",
    "print(note + \"\\n\\n\")\n",
    "\n",
    "# print training info\n",
    "for element in array:\n",
    "    print(element)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# print model info\n",
    "print(\"HYPERPARAMETERS\")\n",
    "print(f\"Model Name: {distiller.name}\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Image Size: {image_size}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Alpha: {alpha}\")\n",
    "print(f\"Beta: {beta}\")\n",
    "print(f\"Temperature: {temperature}\")\n",
    "print(f\"Total runtime: {total_runtime}\")\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "\n",
    "# Reset stdout to its original value\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# Get the captured output\n",
    "captured_output = output_capture.getvalue()\n",
    "\n",
    "\n",
    "# Define the file path\n",
    "file_path = f'/mnt/c/Users/Ann Clarisse Salazar/Documents/project/records_kd/{model_id}/info.txt'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# save to info.txt\n",
    "with open(f\"/mnt/c/Users/Ann Clarisse Salazar/Documents/project/records_kd/{model_id}/info.txt\", 'w') as file:\n",
    "    file.write(captured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
